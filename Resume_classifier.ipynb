{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import pickle\n",
    "from google.colab import files\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to clean resumes\n",
    "def cleanResume(txt):\n",
    "    cleanText = re.sub('http\\S+\\s', ' ', txt)\n",
    "    cleanText = re.sub('RT|cc', ' ', cleanText)\n",
    "    cleanText = re.sub('#\\S+\\s', ' ', cleanText)\n",
    "    cleanText = re.sub('@\\S+', '  ', cleanText)\n",
    "    cleanText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', cleanText)\n",
    "    cleanText = re.sub(r'[^\\x00-\\x7f]', ' ', cleanText)\n",
    "    cleanText = re.sub('\\s+', ' ', cleanText)\n",
    "    return cleanText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the file\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Load the uploaded file into a Pandas DataFrame\n",
    "df = pd.read_csv(next(iter(uploaded)))\n",
    "\n",
    "# Display the dataframe\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the category distribution\n",
    "counts = df['Category'].value_counts()\n",
    "labels = df['Category'].unique()\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.pie(counts, labels=labels, autopct='%1.1f%%', shadow=True, colors=plt.cm.plasma(np.linspace(0,1,len(labels))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the resumes\n",
    "df['CleanedResume'] = df['Resume'].apply(cleanResume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the categories\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "categories_encoded = onehot_encoder.fit_transform(df[['Category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the resumes using TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_vectorizer.fit(df['CleanedResume'])\n",
    "requiredText = tfidf_vectorizer.transform(df['CleanedResume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(requiredText, categories_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf = OneVsRestClassifier(KNeighborsClassifier())\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "ypred = clf.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, ypred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and vectorizer\n",
    "pickle.dump(tfidf_vectorizer, open('tfidf_vectorizer.pkl', 'wb'))\n",
    "pickle.dump(clf, open('model.pkl', 'wb'))\n",
    "pickle.dump(onehot_encoder, open('onehot_encoder.pkl', 'wb'))\n",
    "\n",
    "# Load the trained classifier, vectorizer, and encoder\n",
    "model = pickle.load(open('model.pkl', 'rb'))\n",
    "tfidf_vectorizer = pickle.load(open('tfidf_vectorizer.pkl', 'rb'))\n",
    "onehot_encoder = pickle.load(open('onehot_encoder.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example resume to predict its category\n",
    "myresume = \"\"\"NOOR SAEED\n",
    "\n",
    "ABOUT ME\n",
    "I am a data scientist specializing in machine learning, deep learning, and computer vision. With a strong background in mathematics, statistics, and programming, I am passionate about uncovering hidden patterns and insights in data. I have extensive experience in developing predictive models, implementing deep learning algorithms, and designing computer vision systems. My technical skills include proficiency in Python, Sklearn, TensorFlow, and PyTorch. What sets me apart is my ability to effectively communicate complex concepts to diverse audiences. I excel in translating technical insights into actionable recommendations that drive informed decision-making. If you're looking for a dedicated and versatile data scientist to collaborate on impactful projects, I am eager to contribute my expertise. Let's harness the power of data together to unlock new possibilities and shape a better future.\n",
    "\n",
    "Contact & Sources\n",
    "\n",
    "Email: 611noorsaeed@gmail.com\n",
    "Phone: 03442826192\n",
    "Github: https://github.com/611noorsaeed\n",
    "LinkedIn: https://www.linkedin.com/in/noor-saeed654a23263/\n",
    "Blogs: https://medium.com/@611noorsaeed\n",
    "YouTube: Artificial Intelligence\n",
    "WORK EXPERIENCE\n",
    "\n",
    "Data Scientist\n",
    "XYZ Tech Solutions (Jan 2022 - Present)\n",
    "\n",
    "Developed and deployed machine learning models for predictive analytics, improving accuracy by 15%.\n",
    "Implemented deep learning algorithms for image recognition, achieving a 92% success rate in classification tasks.\n",
    "Designed and optimized recommendation systems, enhancing user engagement by 20%.\n",
    "Conducted statistical analysis and data visualization to support business strategy and decision-making.\n",
    "Junior Data Scientist\n",
    "ABC Analytics (Jun 2020 - Dec 2021)\n",
    "\n",
    "Assisted in developing machine learning models for various business use cases.\n",
    "Participated in data preprocessing and feature engineering for large datasets.\n",
    "Evaluated model performance and provided insights for improvement.\n",
    "Collaborated with cross-functional teams to translate technical findings into business solutions.\n",
    "Intern Data Analyst\n",
    "Data Insight Co. (Jan 2019 - May 2020)\n",
    "\n",
    "Analyzed data trends and patterns to provide actionable insights.\n",
    "Developed data dashboards using Python and SQL to visualize key metrics.\n",
    "Assisted in creating reports and presentations for stakeholders.\n",
    "SKILLS\n",
    "\n",
    "Machine Learning\n",
    "Deep Learning\n",
    "Computer Vision\n",
    "Recommendation Systems\n",
    "Data Visualization\n",
    "Programming Languages (Python, SQL)\n",
    "Data Preprocessing and Feature Engineering\n",
    "Model Evaluation and Deployment\n",
    "Statistical Analysis\n",
    "Communication and Collaboration\n",
    "LANGUAGES\n",
    "\n",
    "English\n",
    "Urdu\n",
    "Hindi\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the input resume\n",
    "cleaned_resume = cleanResume(myresume)\n",
    "\n",
    "# Transform the cleaned resume using the trained TfidfVectorizer\n",
    "input_features = tfidf_vectorizer.transform([cleaned_resume])\n",
    "\n",
    "# Make the prediction using the loaded classifier\n",
    "prediction = model.predict(input_features)\n",
    "prediction_id = onehot_encoder.inverse_transform(prediction)[0][0]\n",
    "\n",
    "# Print the predicted category\n",
    "print(\"Predicted Category:\", prediction_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
